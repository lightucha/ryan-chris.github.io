<!DOCTYPE html>
<html lang=en>
<head>
    <meta charset="utf-8">
    
    <title>서포트 벡터 머신 활용(IRIS) | 고군분투 대학원생의 데이터 분석</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="본 포스팅은 Bigdata X Yonsei 교육 자료임을 밝힙니다. Iris 데이터를 SVM으로 분류하기모델링 과정의 큰 흐름을 되새기면서 실제 iris 데이터에 대한 SVM 모델링을 진행해보자.   12from IPython.display import ImageImage(filename=&apos;images/svm_image5.png&apos;, width=700)  필">
<meta name="keywords" content="Python,Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="서포트 벡터 머신 활용(IRIS)">
<meta property="og:url" content="https://ryan-chris.github.io/2018/07/28/SVM_basic/SVM_실데이터 활용_최종/index.html">
<meta property="og:site_name" content="고군분투 대학원생의 데이터 분석">
<meta property="og:description" content="본 포스팅은 Bigdata X Yonsei 교육 자료임을 밝힙니다. Iris 데이터를 SVM으로 분류하기모델링 과정의 큰 흐름을 되새기면서 실제 iris 데이터에 대한 SVM 모델링을 진행해보자.   12from IPython.display import ImageImage(filename=&apos;images/svm_image5.png&apos;, width=700)  필">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://user-images.githubusercontent.com/29976233/43357177-87173bf0-92b8-11e8-806a-117684a7fc02.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/29976233/43357195-be3b3528-92b8-11e8-89d0-de1684bb02c3.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/29976233/43357249-828a0a08-92b9-11e8-9608-3925dcec07e6.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/29976233/43357268-cfe933be-92b9-11e8-84b8-934e9135def7.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/29976233/43357286-1ad1832c-92ba-11e8-985e-e798ac2a3155.png">
<meta property="og:image" content="https://user-images.githubusercontent.com/29976233/43357302-527bde08-92ba-11e8-8a25-49780e5b76f5.png">
<meta property="og:updated_time" content="2018-07-28T14:03:53.899Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="서포트 벡터 머신 활용(IRIS)">
<meta name="twitter:description" content="본 포스팅은 Bigdata X Yonsei 교육 자료임을 밝힙니다. Iris 데이터를 SVM으로 분류하기모델링 과정의 큰 흐름을 되새기면서 실제 iris 데이터에 대한 SVM 모델링을 진행해보자.   12from IPython.display import ImageImage(filename=&apos;images/svm_image5.png&apos;, width=700)  필">
<meta name="twitter:image" content="https://user-images.githubusercontent.com/29976233/43357177-87173bf0-92b8-11e8-806a-117684a7fc02.png">
    

    
        <link rel="alternate" href="/" title="고군분투 대학원생의 데이터 분석" type="application/atom+xml" />
    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    


</head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">고군분투 대학원생의 데이터 분석</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/about">About</a>
                
                    <a class="main-nav-link" href="/archives">Archives</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/ryan.png" />
                            <i class="fa fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                    <td><a class="main-nav-link" href="/archives">Archives</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile" class="profile-fixed">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/ryan.png" />
            <h2 id="name">Chris Cha</h2>
            <h3 id="title">Data Analyst &amp; ML</h3>
            <span id="location"><i class="fa fa-map-marker"></i>Ulsan, Korea</span>
            <a id="follow" target="_blank" href="https://github.com/ryan-chris/">FOLLOW</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                7
                <span>posts</span>
            </div>
            <div class="article-info-block">
                6
                <span>tags</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="http://github.com/ryan-chris/" target="_blank" title="github" class=tooltip>
                            <i class="fa fa-github"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="facebook" class=tooltip>
                            <i class="fa fa-facebook"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="instagram" class=tooltip>
                            <i class="fa fa-instagram"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="rss" class=tooltip>
                            <i class="fa fa-rss"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main"><article id="post-SVM_basic/SVM_실데이터 활용_최종" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            서포트 벡터 머신 활용(IRIS)
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2018/07/28/SVM_basic/SVM_실데이터 활용_최종/">
            <time datetime="2018-07-28T02:00:03.000Z" itemprop="datePublished">2018-07-28</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/ML/">ML</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/Machine-Learning/">Machine Learning</a>, <a class="tag-link" href="/tags/Python/">Python</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p><em>본 포스팅은 Bigdata X Yonsei 교육 자료임을 밝힙니다.</em></p>
<h1 id="Iris-데이터를-SVM으로-분류하기"><a href="#Iris-데이터를-SVM으로-분류하기" class="headerlink" title="Iris 데이터를 SVM으로 분류하기"></a>Iris 데이터를 SVM으로 분류하기</h1><p>모델링 과정의 큰 흐름을 되새기면서 실제 iris 데이터에 대한 SVM 모델링을 진행해보자.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br><span class="line">Image(filename=<span class="string">'images/svm_image5.png'</span>, width=<span class="number">700</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://user-images.githubusercontent.com/29976233/43357177-87173bf0-92b8-11e8-806a-117684a7fc02.png" alt="Process"></p>
<h2 id="필요한-모듈-import"><a href="#필요한-모듈-import" class="headerlink" title="필요한 모듈 import"></a>필요한 모듈 import</h2><p>먼저 필요한 모듈들을 import한다.</p>
<p>실습에 필요한 패키지 불러오기.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt    </span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> plot_decision_regions <span class="keyword">import</span> plot_decision_regions</span><br></pre></td></tr></table></figure></p>
<h2 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><p>scikit-learn에서 Iris 데이터를 가져오자.<br>Iris 데이터는 통계학자인 피셔가 소개한 데이터로, 붓꽃의 3가지 종에 대해 꽃받침sepal과 꽃잎petal의 길이를 정리한 데이터다</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Image(filename=<span class="string">'images/Iris_img.png'</span>, width=<span class="number">700</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://user-images.githubusercontent.com/29976233/43357195-be3b3528-92b8-11e8-89d0-de1684bb02c3.png" alt="Iris"></p>
<p>sklearn 라이브러리에서 datasets를 불러온다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"><span class="comment"># iris데이터는 load_iris()함수를 사용해 불러올 수 있다.</span></span><br><span class="line">iris = datasets.load_iris()</span><br></pre></td></tr></table></figure></p>
<p>iris 내부를 들여다보자<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iris</span><br></pre></td></tr></table></figure></p>
<pre><code>{&apos;data&apos;: array([[5.1, 3.5, 1.4, 0.2],
        [4.9, 3. , 1.4, 0.2],
        [4.7, 3.2, 1.3, 0.2],
        [4.6, 3.1, 1.5, 0.2],

        ... 중  략 ...

        [6.3, 2.5, 5. , 1.9],
        [6.5, 3. , 5.2, 2. ],
        [6.2, 3.4, 5.4, 2.3],
        [5.9, 3. , 5.1, 1.8]]),
 &apos;target&apos;: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),
 &apos;target_names&apos;: array([&apos;setosa&apos;, &apos;versicolor&apos;, &apos;virginica&apos;], dtype=&apos;&lt;U10&apos;),
 &apos;DESCR&apos;: &apos;Iris Plants Database\n====================\n\nNotes\n-----\nData Set Characteristics:\n    :Number of Instances: 150 (50 in each of three classes)\n    :Number of Attributes: 4 numeric, predictive attributes and the class\n    :Attribute Information:\n        - sepal length in cm\n        - sepal width in cm\n        - petal length in cm\n        - petal width in cm\n        - class:\n                - Iris-Setosa\n                - Iris-Versicolour\n                - Iris-Virginica\n    :Summary Statistics:\n\n    ============== ==== ==== ======= ===== ====================\n                    Min  Max   Mean    SD   Class Correlation\n    ============== ==== ==== ======= ===== ====================\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n    ============== ==== ==== ======= ===== ====================\n\n    :Missing Attribute Values: None\n    :Class Distribution: 33.3% for each of 3 classes.\n    :Creator: R.A. Fisher\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n    :Date: July, 1988\n\nThis is a copy of UCI ML iris datasets.\nhttp://archive.ics.uci.edu/ml/datasets/Iris\n\nThe famous Iris database, first used by Sir R.A Fisher\n\nThis is perhaps the best known database to be found in the\npattern recognition literature.  Fisher\&apos;s paper is a classic in the field and\nis referenced frequently to this day.  (See Duda &amp; Hart, for example.)  The\ndata set contains 3 classes of 50 instances each, where each class refers to a\ntype of iris plant.  One class is linearly separable from the other 2; the\nlatter are NOT linearly separable from each other.\n\nReferences\n----------\n   - Fisher,R.A. &quot;The use of multiple measurements in taxonomic problems&quot;\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to\n     Mathematical Statistics&quot; (John Wiley, NY, 1950).\n   - Duda,R.O., &amp; Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n     (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.\n   - Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System\n     Structure and Classification Rule for Recognition in Partially Exposed\n     Environments&quot;.  IEEE Transactions on Pattern Analysis and Machine\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n   - Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;.  IEEE Transactions\n     on Information Theory, May 1972, 431-433.\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al&quot;s AUTOCLASS II\n     conceptual clustering system finds 3 classes in the data.\n   - Many, many more ...\n&apos;,
 &apos;feature_names&apos;: [&apos;sepal length (cm)&apos;,
  &apos;sepal width (cm)&apos;,
  &apos;petal length (cm)&apos;,
  &apos;petal width (cm)&apos;]}
</code></pre><p>첫번째(sepal length)와 세번째(petal length) 변수만 추출하여 X로 할당하고, 타겟 변수만 추출하여 y로 할당하자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = iris.data[:, [<span class="number">0</span>, <span class="number">2</span>]]</span><br><span class="line">y = iris.target</span><br></pre></td></tr></table></figure></p>
<p>y의 라벨값을 확인해보자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Class labels:'</span>, np.unique(y))</span><br></pre></td></tr></table></figure></p>
<pre><code>Class labels: [0 1 2]
</code></pre><h2 id="학습세트와-테스트-세트-나누기"><a href="#학습세트와-테스트-세트-나누기" class="headerlink" title="학습세트와 테스트 세트 나누기"></a>학습세트와 테스트 세트 나누기</h2><p>데이터의 70%를 training에 사용하고 나머지 30%를 test에 사용하기 위해 <strong>split</strong>한다.<br></p>
<p>sklearn 라이브러리에서 제공하는 train_test_split 함수를 불러오자<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure></p>
<p>test_size의 비율을 30%로, 시드넘버는 1로, 층화추출하여 데이터를 나누자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">1</span>, stratify=y)</span><br></pre></td></tr></table></figure></p>
<p>데이터가 비율에 맞게 잘 나누어졌는지 확인해보자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Labels counts in y:'</span>, len(y))</span><br><span class="line">print(<span class="string">'Labels counts in y_train:'</span>, len(y_train))</span><br><span class="line">print(<span class="string">'Labels counts in y_test:'</span>, len(y_test))</span><br></pre></td></tr></table></figure></p>
<pre><code>Labels counts in y: 150
Labels counts in y_train: 105
Labels counts in y_test: 45
</code></pre><h2 id="독립변수-Scaling-하기"><a href="#독립변수-Scaling-하기" class="headerlink" title="독립변수 Scaling 하기"></a>독립변수 Scaling 하기</h2><p>X_train의 통계값을 이용하여 <strong>정규화</strong>시킴. PCA 등을 할 때 필요하다.<br>실습수업에서는 과정을 이해하기 위해 진행해보도록 하자.</p>
<p>sklearn 라이브러리에서 제공하는 StandardScaler라는 정규화 함수를 사용하자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br></pre></td></tr></table></figure></p>
<p>StandardScaler 함수의 인스턴스인 sc라는 객체를 만들어 X_train 데이터를 넣어보자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sc = StandardScaler()</span><br><span class="line">sc.fit(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># X_train이 피팅되어 평균과 분산을 구할수 있다.</span></span><br><span class="line">print(<span class="string">'mean of X_train:'</span>,sc.mean_)</span><br><span class="line">print(<span class="string">'var of X_train:'</span>,sc.var_)</span><br></pre></td></tr></table></figure></p>
<pre><code>mean of X_train: [5.85714286 3.78952381]
var of X_train: [0.6894966  3.21484263]
</code></pre><p>이번에는 X_train과 X_test데이터를 평균 0, 표준편차 1로 정규화 시켜보도록 하자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train_std = sc.transform(X_train)</span><br><span class="line">X_test_std = sc.transform(X_test)</span><br></pre></td></tr></table></figure></p>
<p>출력해서 X_train_std를 확인해보자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(X_train_std)</span><br></pre></td></tr></table></figure></p>
<pre><code>[[-0.4301064  -1.33269725]
 [-0.55053619 -1.16537974]
 [ 0.65376173  0.84243039]
 [ 1.0150511   1.0655204 ]
 .......중    략........
 [-1.63440432 -1.38846976]
 [-0.06881702  0.11738784]
 [-1.03225536 -1.22115225]
 [-1.51397453 -1.27692475]
 [-1.75483411 -1.38846976]]
</code></pre><p>X_train_std의 평균과 표준편차를 확인해보자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Mean of X_train_std :'</span>,np.mean(X_train_std[:,<span class="number">0</span>]), np.mean(X_train_std[:,<span class="number">1</span>]))</span><br><span class="line">print(<span class="string">'Std of X_train_std :'</span>,np.std(X_train_std[:,<span class="number">0</span>]), np.std(X_train_std[:,<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></p>
<pre><code>Mean of X_train_std : 1.541623971336646e-15 1.1207965772406342e-16
Std of X_train_std : 1.0 1.0
</code></pre><h2 id="C가-작은-경우-오분류를-관대하게-허용"><a href="#C가-작은-경우-오분류를-관대하게-허용" class="headerlink" title="C가 작은 경우(오분류를 관대하게 허용)"></a>C가 작은 경우(오분류를 관대하게 허용)</h2><p>SVC 클래스에 kernel=’linear’, 시드넘버는 1, C=0.1로 두고 모델을 피팅시키자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">svm_smallc = SVC(kernel=<span class="string">'linear'</span>, random_state=<span class="number">1</span>, C=<span class="number">0.1</span>)</span><br><span class="line">svm_smallc.fit(X_train_std, y_train)</span><br></pre></td></tr></table></figure></p>
<pre><code>SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&apos;ovr&apos;, degree=3, gamma=&apos;auto&apos;, kernel=&apos;linear&apos;,
  max_iter=-1, probability=False, random_state=1, shrinking=True,
  tol=0.001, verbose=False)
</code></pre><p>데이터를 모두 펼쳐놓고 결정경계 그림을 그리고자 한다.<br>train과 test로 나누었던 데이터를 다시 합쳐보자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_combined_std = np.vstack((X_train_std, X_test_std))</span><br><span class="line">y_combined = np.hstack((y_train, y_test))</span><br></pre></td></tr></table></figure></p>
<p>데이터를 모두 표시하고 결정경계를 보여주는 plot_decision_regions 함수를 이용하자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plot_decision_regions(X=X_combined_std, y=y_combined,</span><br><span class="line">                      classifier=svm_smallc, test_idx=range(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.xlabel(<span class="string">'petal length [standardized]'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'petal width [standardized]'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br></pre></td></tr></table></figure></p>
<pre><code>&lt;matplotlib.legend.Legend at 0x2a88129d438&gt;
</code></pre><p><img src="https://user-images.githubusercontent.com/29976233/43357249-828a0a08-92b9-11e8-9608-3925dcec07e6.png" alt="Figure 1."></p>
<h2 id="모델-평가하기-svm-smallc"><a href="#모델-평가하기-svm-smallc" class="headerlink" title="모델 평가하기 - svm_smallc"></a>모델 평가하기 - svm_smallc</h2><p>svm_smallc모델에 X_test_std데이터를 넣어 y값을 예측한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_pred = svm_smallc.predict(X_test_std)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 실제 y_pred값을 확인하고, y_test값과 y_pred값이 다른 것이 있는지 확인한다.</span></span><br><span class="line">y_pred,(y_test != y_pred)</span><br></pre></td></tr></table></figure></p>
<pre><code>(array([2, 0, 0, 1, 2, 1, 2, 1, 2, 0, 0, 1, 0, 1, 0, 2, 2, 1, 1, 2, 2, 0,
        2, 1, 1, 1, 1, 2, 0, 1, 0, 0, 1, 1, 2, 2, 0, 0, 0, 2, 2, 1, 2, 0,
        0]),
 array([False, False, False,  True,  True, False, False, False, False,
        False, False,  True, False, False, False,  True, False, False,
        False, False, False, False,  True,  True, False, False, False,
        False, False,  True, False, False, False, False, False, False,
        False, False, False,  True, False,  True,  True, False, False]))
</code></pre><p>y_test와 y_pred가 다른 값이 몇개 있는지 확인한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Misclassified samples: %d'</span> % (y_test != y_pred).sum())</span><br></pre></td></tr></table></figure></p>
<pre><code>Misclassified samples: 10
</code></pre><p>sklearn 라이브러리에서 정확도를 구하는 accuracy_score 함수를 불러온다.</p>
<blockquote>
<p>y_test와 y_pred을 넣고 정확도를 계산한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Accuracy: %.2f'</span> % accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></p>
</blockquote>
<pre><code>Accuracy: 0.78
</code></pre><h2 id="C가-큰-경우-오분류를-엄격하게-규제"><a href="#C가-큰-경우-오분류를-엄격하게-규제" class="headerlink" title="C가 큰 경우(오분류를 엄격하게 규제)"></a>C가 큰 경우(오분류를 엄격하게 규제)</h2><p>SVC 클래스에 kernel=’linear’, 시드넘버는 1, C=10로 두고 모델을 피팅시키자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">svm_largec = SVC(kernel=<span class="string">'linear'</span>, random_state=<span class="number">1</span>, C=<span class="number">10</span>)</span><br><span class="line">svm_largec.fit(X_train_std, y_train)</span><br></pre></td></tr></table></figure></p>
<pre><code>SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&apos;ovr&apos;, degree=3, gamma=&apos;auto&apos;, kernel=&apos;linear&apos;,
  max_iter=-1, probability=False, random_state=1, shrinking=True,
  tol=0.001, verbose=False)
</code></pre><p>데이터를 모두 표시하고 결정경계를 보여주는 plot_decision_regions 함수를 이용하자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plot_decision_regions(X=X_combined_std, y=y_combined,</span><br><span class="line">                      classifier=svm_largec, test_idx=range(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.xlabel(<span class="string">'petal length [standardized]'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'petal width [standardized]'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br></pre></td></tr></table></figure></p>
<pre><code>&lt;matplotlib.legend.Legend at 0x2a8812de748&gt;
</code></pre><p><img src="https://user-images.githubusercontent.com/29976233/43357268-cfe933be-92b9-11e8-84b8-934e9135def7.png" alt="Figure 2."></p>
<h2 id="모델-평가하기-svm-largec"><a href="#모델-평가하기-svm-largec" class="headerlink" title="모델 평가하기 - svm_largec"></a>모델 평가하기 - svm_largec</h2><p>svm_largec모델에 X_test_std데이터를 넣어 y값을 예측한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_pred = svm_largec.predict(X_test_std)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 실제 y_pred값을 확인하고, y_test값과 y_pred값이 다른 것이 있는지 확인한다.</span></span><br><span class="line">y_pred,(y_test != y_pred)</span><br></pre></td></tr></table></figure></p>
<pre><code>(array([2, 0, 0, 1, 1, 1, 2, 1, 2, 0, 0, 2, 0, 1, 0, 1, 2, 1, 1, 2, 2, 0,
        1, 2, 1, 1, 1, 2, 0, 2, 0, 0, 1, 1, 2, 2, 0, 0, 0, 1, 2, 2, 1, 0,
        0]),
 array([False, False, False,  True, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False]))
</code></pre><p>y_test와 y_pred가 다른 값이 몇개 있는지 확인한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Misclassified samples: %d'</span> % (y_test != y_pred).sum())</span><br></pre></td></tr></table></figure></p>
<pre><code>Misclassified samples: 1
</code></pre><p>sklearn 라이브러리에서 정확도를 구하는 accuracy_score 함수를 불러온다.</p>
<blockquote>
<p>y_test와 y_pred을 넣고 정확도를 계산한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Accuracy: %.2f'</span> % accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></p>
</blockquote>
<pre><code>Accuracy: 0.98
</code></pre><h1 id="Kernel-SVM-gamma의-값에-따른-결정경계면의-변화"><a href="#Kernel-SVM-gamma의-값에-따른-결정경계면의-변화" class="headerlink" title="Kernel SVM : gamma의 값에 따른 결정경계면의 변화"></a>Kernel SVM : gamma의 값에 따른 결정경계면의 변화</h1><h2 id="gamma가-작을때-1"><a href="#gamma가-작을때-1" class="headerlink" title="gamma가 작을때 : 1"></a>gamma가 작을때 : 1</h2><p>SVC 클래스에 kernel=’rbf’, 시드넘버는 1, gamma=1로 두고 모델을 피팅시키자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">svm_k_smallg = SVC(kernel=<span class="string">'rbf'</span>, random_state=<span class="number">1</span>, gamma=<span class="number">1</span>)</span><br><span class="line">svm_k_smallg.fit(X_train_std, y_train)</span><br></pre></td></tr></table></figure></p>
<pre><code>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&apos;ovr&apos;, degree=3, gamma=1, kernel=&apos;rbf&apos;,
  max_iter=-1, probability=False, random_state=1, shrinking=True,
  tol=0.001, verbose=False)
</code></pre><p>데이터를 모두 표시하고 결정경계를 보여주는 plot_decision_regions 함수를 이용하자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plot_decision_regions(X_combined_std, y_combined,</span><br><span class="line">                      classifier=svm_k_smallg, test_idx=range(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.xlabel(<span class="string">'petal length [standardized]'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'petal width [standardized]'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br></pre></td></tr></table></figure></p>
<pre><code>&lt;matplotlib.legend.Legend at 0x2a88137a908&gt;
</code></pre><p><img src="https://user-images.githubusercontent.com/29976233/43357286-1ad1832c-92ba-11e8-985e-e798ac2a3155.png" alt="Figure 3."></p>
<h2 id="모델-평가하기-svm-k-smallg"><a href="#모델-평가하기-svm-k-smallg" class="headerlink" title="모델 평가하기 - svm_k_smallg"></a>모델 평가하기 - svm_k_smallg</h2><p>svm_k_smallg모델에 X_test_std데이터를 넣어 y값을 예측한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_pred = svm_k_smallg.predict(X_test_std)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 실제 y_pred값을 확인하고, y_test값과 y_pred값이 다른 것이 있는지 확인한다.</span></span><br><span class="line">y_pred,(y_test != y_pred)</span><br></pre></td></tr></table></figure></p>
<pre><code>(array([2, 0, 0, 1, 1, 1, 2, 1, 2, 0, 0, 1, 0, 1, 0, 1, 2, 1, 1, 2, 2, 0,
        1, 1, 1, 1, 1, 2, 0, 1, 0, 0, 1, 1, 2, 2, 0, 0, 0, 1, 2, 2, 1, 0,
        0]),
 array([False, False, False,  True, False, False, False, False, False,
        False, False,  True, False, False, False, False, False, False,
        False, False, False, False, False,  True, False, False, False,
        False, False,  True, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False]))
</code></pre><p>y_test와 y_pred가 다른 값이 몇개 있는지 확인한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Misclassified samples: %d'</span> % (y_test != y_pred).sum())</span><br></pre></td></tr></table></figure></p>
<pre><code>Misclassified samples: 4
</code></pre><p>sklearn 라이브러리에서 정확도를 구하는 accuracy_score 함수를 불러온다.</p>
<blockquote>
<p>y_test와 y_pred을 넣고 정확도를 계산한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Accuracy: %.2f'</span> % accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure></p>
</blockquote>
<pre><code>Accuracy: 0.91
</code></pre><h2 id="gamma가-클때-100"><a href="#gamma가-클때-100" class="headerlink" title="gamma가 클때 : 100"></a>gamma가 클때 : 100</h2><p>SVC 클래스에 kernel=’rbf’, 시드넘버는 1, gamma=100로 두고 모델을 피팅시키자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">svm_k_largeg = SVC(kernel=<span class="string">'rbf'</span>, random_state=<span class="number">1</span>, gamma=<span class="number">100</span>)</span><br><span class="line">svm_k_largeg.fit(X_train_std, y_train)</span><br></pre></td></tr></table></figure></p>
<pre><code>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&apos;ovr&apos;, degree=3, gamma=100, kernel=&apos;rbf&apos;,
  max_iter=-1, probability=False, random_state=1, shrinking=True,
  tol=0.001, verbose=False)
</code></pre><p>데이터를 모두 표시하고 결정경계를 보여주는 plot_decision_regions 함수를 이용하자.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plot_decision_regions(X_combined_std, y_combined,</span><br><span class="line">                      classifier=svm_k_largeg, test_idx=range(<span class="number">105</span>, <span class="number">150</span>))</span><br><span class="line">plt.xlabel(<span class="string">'petal length [standardized]'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'petal width [standardized]'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br></pre></td></tr></table></figure></p>
<pre><code>&lt;matplotlib.legend.Legend at 0x2a8813facc0&gt;
</code></pre><p><img src="https://user-images.githubusercontent.com/29976233/43357302-527bde08-92ba-11e8-8a25-49780e5b76f5.png" alt="Figure 4."></p>
<h2 id="모델-평가하기-svm-k-largeg"><a href="#모델-평가하기-svm-k-largeg" class="headerlink" title="모델 평가하기 - svm_k_largeg"></a>모델 평가하기 - svm_k_largeg</h2><p>svm_k_largeg모델에 X_test_std데이터를 넣어 y값을 예측한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_pred = svm_k_largeg.predict(X_test_std)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 실제 y_pred값을 확인하고, y_test값과 y_pred값이 다른 것이 있는지 확인한다.</span></span><br><span class="line">y_pred,(y_test != y_pred)</span><br></pre></td></tr></table></figure></p>
<pre><code>(array([2, 0, 0, 2, 1, 1, 2, 1, 2, 0, 0, 2, 0, 1, 0, 1, 1, 1, 1, 2, 2, 0,
        1, 2, 1, 2, 1, 2, 0, 2, 0, 0, 1, 1, 2, 2, 0, 0, 0, 1, 2, 2, 1, 0,
        0]),
 array([False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False,  True, False,
        False, False, False, False, False, False, False,  True, False,
        False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False]))
</code></pre><p>y_test와 y_pred가 다른 값이 몇개 있는지 확인한다.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Misclassified samples: %d'</span> % (y_test != y_pred).sum())</span><br></pre></td></tr></table></figure></p>
<pre><code>Misclassified samples: 2
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sklearn 라이브러리에서 정확도를 구하는 accuracy_score 함수를 불러온다.</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># y_test와 y_pred을 넣고 정확도를 계산한다.</span></span><br><span class="line">print(<span class="string">'Accuracy: %.2f'</span> % accuracy_score(y_test, y_pred))</span><br></pre></td></tr></table></figure>
<pre><code>Accuracy: 0.96
</code></pre>
        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://ryan-chris.github.io/2018/07/28/SVM_basic/SVM_실데이터 활용_최종/" data-id="cjk5hleyb0000hwm30222i35r" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/08/09/git_pr/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Newer</strong>
            <div class="article-nav-title">
                
                    초짜의 Git Pull-Request(PR)
                
            </div>
        </a>
    
    
        <a href="/2018/07/27/SVM_basic/SVM_기초_학생용/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">서포트 벡터 머신 기초(SVM, Support Vector Machine)</div>
        </a>
    
</nav>


    
</article>


    
    

</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">recent</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/08/09/git_pr/" class="thumbnail">
    
    
        <span style="background-image:url(https://user-images.githubusercontent.com/29976233/43906946-691e71d8-9c2f-11e8-8b7d-270548463431.png)" alt="초짜의 Git Pull-Request(PR)" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Git/">Git</a></p>
                            <p class="item-title"><a href="/2018/08/09/git_pr/" class="title">초짜의 Git Pull-Request(PR)</a></p>
                            <p class="item-date"><time datetime="2018-08-09T14:00:03.000Z" itemprop="datePublished">2018-08-09</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/28/SVM_basic/SVM_실데이터 활용_최종/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/ML/">ML</a></p>
                            <p class="item-title"><a href="/2018/07/28/SVM_basic/SVM_실데이터 활용_최종/" class="title">서포트 벡터 머신 활용(IRIS)</a></p>
                            <p class="item-date"><time datetime="2018-07-28T02:00:03.000Z" itemprop="datePublished">2018-07-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/27/SVM_basic/SVM_기초_학생용/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/ML/">ML</a></p>
                            <p class="item-title"><a href="/2018/07/27/SVM_basic/SVM_기초_학생용/" class="title">서포트 벡터 머신 기초(SVM, Support Vector Machine)</a></p>
                            <p class="item-date"><time datetime="2018-07-27T02:45:03.000Z" itemprop="datePublished">2018-07-27</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/17/basic-pandas-3/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python/">Python</a></p>
                            <p class="item-title"><a href="/2018/07/17/basic-pandas-3/" class="title">판다스 기초 03</a></p>
                            <p class="item-date"><time datetime="2018-07-17T14:50:03.000Z" itemprop="datePublished">2018-07-17</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2018/07/16/basic-pandas-2/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Python/">Python</a></p>
                            <p class="item-title"><a href="/2018/07/16/basic-pandas-2/" class="title">판다스 기초 02</a></p>
                            <p class="item-date"><time datetime="2018-07-16T13:18:03.000Z" itemprop="datePublished">2018-07-16</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Git/">Git</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ML/">ML</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">3</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a><span class="archive-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PR/">PR</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pandas/">Pandas</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pull-Request/">Pull-Request</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/Machine-Learning/" style="font-size: 13.33px;">Machine Learning</a> <a href="/tags/PR/" style="font-size: 10px;">PR</a> <a href="/tags/Pandas/" style="font-size: 16.67px;">Pandas</a> <a href="/tags/Pull-Request/" style="font-size: 10px;">Pull-Request</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/git/" style="font-size: 10px;">git</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2018 Ukhyeon Chris Cha<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        


    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>